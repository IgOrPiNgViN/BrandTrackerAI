#!/usr/bin/env python3
"""
–ü—Ä–æ—Å—Ç–æ–π –ø–∞—Ä—Å–µ—Ä –æ—Ç–∑—ã–≤–æ–≤ —Å 2–ì–ò–° –∏–∑ HTML —Ñ–∞–π–ª–∞
"""

import requests
import re
import os
from typing import List, Dict, Optional
from bs4 import BeautifulSoup
import logging
from datetime import datetime
import csv

class SimpleTwoGisParser:
    """–ü—Ä–æ—Å—Ç–æ–π –ø–∞—Ä—Å–µ—Ä –æ—Ç–∑—ã–≤–æ–≤ —Å 2–ì–ò–°"""

    def __init__(self):
        self.logger = logging.getLogger('SimpleTwoGisParser')

    def parse_reviews_from_url(self, url: str, limit: int = 1000, max_pages: int = 30) -> List[Dict]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–∑—ã–≤–æ–≤ —Å 2–ì–ò–° –ø–æ URL"""
        self.logger.info(f"üåê –ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–∑—ã–≤–æ–≤ —Å 2–ì–ò–° URL: {url} (–ª–∏–º–∏—Ç: {limit}, —Å—Ç—Ä–∞–Ω–∏—Ü: {max_pages})")
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º ID –±–∏–∑–Ω–µ—Å–∞
        business_id = self._extract_business_id(url)
        if not business_id:
            self.logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å ID –±–∏–∑–Ω–µ—Å–∞ –∏–∑ URL")
            return []
        
        all_reviews = []
        review_counter = 0
        consecutive_empty_pages = 0
        
        for page in range(1, max_pages + 1):
            page_url = self._build_page_url(url, page)
            self.logger.info(f"üìÑ –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É {page}: {page_url}")
            
            html_content = self._download_page(page_url)
            if not html_content:
                self.logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É {page}")
                consecutive_empty_pages += 1
                if consecutive_empty_pages >= 3:
                    self.logger.info(f"‚èπÔ∏è –ü—Ä–µ–∫—Ä–∞—â–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥: 3 —Å—Ç—Ä–∞–Ω–∏—Ü—ã –ø–æ–¥—Ä—è–¥ –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å")
                    break
                continue
            
            page_reviews = self._extract_reviews_from_html(html_content, business_id, limit, review_counter)
            
            if len(page_reviews) == 0:
                consecutive_empty_pages += 1
                self.logger.warning(f"‚ö†Ô∏è –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page}: –Ω–∞–π–¥–µ–Ω–æ 0 –æ—Ç–∑—ã–≤–æ–≤ (–ø—É—Å—Ç—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü –ø–æ–¥—Ä—è–¥: {consecutive_empty_pages})")
                if consecutive_empty_pages >= 3:
                    self.logger.info(f"‚èπÔ∏è –ü—Ä–µ–∫—Ä–∞—â–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥: –¥–æ—Å—Ç–∏–≥–Ω—É—Ç –∫–æ–Ω–µ—Ü –æ—Ç–∑—ã–≤–æ–≤ (3 –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –ø–æ–¥—Ä—è–¥)")
                    break
            else:
                consecutive_empty_pages = 0
                review_counter += len(page_reviews)
                all_reviews.extend(page_reviews)
                self.logger.info(f"üìä –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page}: –Ω–∞–π–¥–µ–Ω–æ {len(page_reviews)} –æ—Ç–∑—ã–≤–æ–≤, –≤—Å–µ–≥–æ: {len(all_reviews)}")
            
            if page < max_pages:
                import time
                import random
                from core.config import REQUEST_DELAY_SECONDS
                delay = random.uniform(REQUEST_DELAY_SECONDS, REQUEST_DELAY_SECONDS * 2)
                time.sleep(delay)
        
        self.logger.info(f"‚úÖ –í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ –æ—Ç–∑—ã–≤–æ–≤: {len(all_reviews)}")
        return all_reviews

    def _extract_business_id(self, url: str) -> Optional[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ ID –±–∏–∑–Ω–µ—Å–∞ –∏–∑ URL 2–ì–ò–°"""
        match = re.search(r'/firm/(\d+)', url)
        return match.group(1) if match else None

    def _build_page_url(self, base_url: str, page: int) -> str:
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ URL –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã 2–ì–ò–°"""
        # –£–±–∏—Ä–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–∞–≥–∏–Ω–∞—Ü–∏–∏
        base_url = re.sub(r'[?&]page=\d+', '', base_url)
        base_url = re.sub(r'[?&]p=\d+', '', base_url)
        
        # –î–ª—è –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –±–∞–∑–æ–≤—ã–π URL
        if page == 1:
            return base_url
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        separator = '&' if '?' in base_url else '?'
        return f"{base_url}{separator}page={page}"

    def _download_page(self, url: str) -> Optional[str]:
        """–°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
            
            response = requests.get(url, headers=headers, timeout=10)
            response.raise_for_status()
            
            return response.text
            
        except Exception as e:
            self.logger.warning(f"‚ùå –û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è {url}: {e}")
            return None

    def _extract_reviews_from_html(self, html_content: str, business_id: str, limit: int, start_counter: int = 0) -> List[Dict]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –æ—Ç–∑—ã–≤–æ–≤ –∏–∑ HTML 2–ì–ò–°"""
        soup = BeautifulSoup(html_content, 'html.parser')
        reviews = []
        
        # –ò—â–µ–º –±–ª–æ–∫–∏ –æ—Ç–∑—ã–≤–æ–≤ –≤ 2–ì–ò–° –ø–æ —Ä–∞–∑–Ω—ã–º —Å–µ–ª–µ–∫—Ç–æ—Ä–∞–º
        review_blocks = soup.find_all('div', class_='_1k5soqfl')
        
        # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã
        if not review_blocks:
            review_blocks = soup.find_all('div', attrs={'data-review-id': True})
        if not review_blocks:
            review_blocks = soup.find_all('div', class_=re.compile(r'review|Review|–æ—Ç–∑—ã–≤', re.I))
        
        self.logger.info(f"üîç –ù–∞–π–¥–µ–Ω–æ –±–ª–æ–∫–æ–≤ –æ—Ç–∑—ã–≤–æ–≤: {len(review_blocks)}")
        
        for i, block in enumerate(review_blocks):
            try:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –æ—Ç–∑—ã–≤–∞
                text_element = block.find('div', class_='_49x36f')
                
                # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è —Ç–µ–∫—Å—Ç–∞
                if not text_element:
                    text_element = block.find('div', class_=re.compile(r'text|Text|—Ç–µ–∫—Å—Ç', re.I))
                if not text_element:
                    # –ò—â–µ–º –ª—é–±–æ–π div —Å –¥–ª–∏–Ω–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º
                    text_elements = block.find_all('div')
                    for elem in text_elements:
                        text = elem.get_text(strip=True)
                        if 50 <= len(text) <= 5000:
                            text_element = elem
                            break
                
                if text_element:
                    text = text_element.get_text(strip=True)
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –æ—Ç–∑—ã–≤ –≥–æ—Å—Ç—è
                    if self._is_guest_review(text):
                        # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ
                        author = self._extract_author(block)
                        rating = self._extract_rating(block)
                        date = self._extract_date(block)
                        
                        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ
                        author = self._clean_author_name(author)
                        date = self._clean_date_text(date)
                        
                        # –°–æ–∑–¥–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π ID
                        review_id = f"{business_id}_{start_counter + len(reviews)}"
                        
                        review = {
                            'id': review_id,
                            'text': text,
                            'rating': rating,
                            'author': author,
                            'date': date,
                            'source': '2GIS'
                        }
                        
                        reviews.append(review)
                        self.logger.debug(f"‚úÖ –ù–∞–π–¥–µ–Ω –æ—Ç–∑—ã–≤ {len(reviews)}: {text[:50]}...")
                        
            except Exception as e:
                self.logger.debug(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –±–ª–æ–∫–∞ {i}: {e}")
                continue
        
        return reviews

    def _is_guest_review(self, text: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞, —á—Ç–æ —ç—Ç–æ –æ—Ç–∑—ã–≤ –≥–æ—Å—Ç—è (–Ω–µ –æ—Ç–≤–µ—Ç —Ä–µ—Å—Ç–æ—Ä–∞–Ω–∞)"""
        if not text or not isinstance(text, str):
            return False
        
        text_lower = text.lower()
        
        # –ò—Å–∫–ª—é—á–∞–µ–º –æ—Ç–≤–µ—Ç—ã —Ä–µ—Å—Ç–æ—Ä–∞–Ω–∞
        restaurant_response_keywords = [
            '—Å–ø–∞—Å–∏–±–æ –∑–∞ –æ—Ç–∑—ã–≤', '–±–ª–∞–≥–æ–¥–∞—Ä–∏–º –∑–∞ –æ—Ç–∑—ã–≤', '—Ä–∞–¥—ã —á—Ç–æ –≤–∞–º –ø–æ–Ω—Ä–∞–≤–∏–ª–æ—Å—å',
            '–ø—Ä–∏–Ω–æ—Å–∏–º –∏–∑–≤–∏–Ω–µ–Ω–∏—è', '–º—ã —Ä–∞–±–æ—Ç–∞–µ–º –Ω–∞–¥', '–Ω–∞—à–∞ –∫–æ–º–∞–Ω–¥–∞',
            '–∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ü–∏—è —Ä–µ—Å—Ç–æ—Ä–∞–Ω–∞', '–º–µ–Ω–µ–¥–∂–µ—Ä —Ä–µ—Å—Ç–æ—Ä–∞–Ω–∞', '—É–ø—Ä–∞–≤–ª—è—é—â–∏–π',
            '–º—ã —Ü–µ–Ω–∏–º', '–º—ã —Å—Ç—Ä–µ–º–∏–º—Å—è', '–Ω–∞—à–∞ —Ü–µ–ª—å', '–º—ã —Å—Ç–∞—Ä–∞–µ–º—Å—è',
            '–≤–¥–æ—Ö–Ω–æ–≤–ª—è–µ—Ç–µ', '–∑–∞–ª–µ—Ç–∞–π –Ω–∞ –∑–∞–≤—Ç—Ä–∞–∫–∏', '–æ–±–Ω—è–ª–∏ –≤—Å–µ–π –∫–æ–º–∞–Ω–¥–æ–π'
        ]
        
        if any(keyword in text_lower for keyword in restaurant_response_keywords):
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –Ω–µ —Å–ª—É–∂–µ–±–Ω—ã–π —Ç–µ–∫—Å—Ç (—É–±—Ä–∞–ª–∏ 2gis, maps, http, https)
        not_service_text = not any(service_word in text_lower for service_word in [
            'cookie', 'javascript', 'script', 'function', 'var ', 'let ', 'const ',
            'html', 'css', 'class=', 'id=', 'href=', 'src=', 'alt=',
            'api', 'json', 'xml'
        ])
        
        # –ë–æ–ª–µ–µ –º—è–≥–∫–∏–µ –ø—Ä–æ–≤–µ—Ä–∫–∏
        has_spaces = ' ' in text
        has_letters = bool(re.search(r'[–∞-—è—ë–ê-–Ø–Åa-zA-Z]', text))
        not_too_short = len(text) > 20  # –ë—ã–ª–æ 50
        not_too_long = len(text) < 5000  # –ë—ã–ª–æ 1000
        
        return (has_spaces and has_letters and not_too_short and not_too_long and not_service_text)

    def _extract_author(self, block) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞–≤—Ç–æ—Ä–∞ –∏–∑ –±–ª–æ–∫–∞ 2–ì–ò–°"""
        try:
            # –ò—â–µ–º –∏–º—è –∞–≤—Ç–æ—Ä–∞ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —Å–µ–ª–µ–∫—Ç–æ—Ä–µ
            author_element = block.find('span', class_='_16s5yj36')
            if author_element:
                author_text = author_element.get_text(strip=True)
                cleaned = self._clean_author_name(author_text)
                if cleaned:
                    return cleaned
            
            return "–ê–Ω–æ–Ω–∏–º"
        except:
            return "–ê–Ω–æ–Ω–∏–º"

    def _clean_author_name(self, author_text: str) -> str:
        """–û—á–∏—Å—Ç–∫–∞ –∏–º–µ–Ω–∏ –∞–≤—Ç–æ—Ä–∞"""
        try:
            # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–π —Ç–µ–∫—Å—Ç
            unwanted_patterns = [
                r'–ü–æ–ª–µ–∑–Ω–æ\s*\d*',
                r'–ß–∏—Ç–∞—Ç—å —Ü–µ–ª–∏–∫–æ–º',
                r'–û—Ç–≤–µ—Ç–∏—Ç—å',
                r'–ü–æ–∂–∞–ª–æ–≤–∞—Ç—å—Å—è',
                r'\s+',
                r'^\s+|\s+$'
            ]
            cleaned = author_text
            for pattern in unwanted_patterns:
                cleaned = re.sub(pattern, '', cleaned, flags=re.IGNORECASE)
            
            # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º
            cleaned = re.sub(r'\s+', ' ', cleaned).strip()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –æ—Å—Ç–∞–ª–æ—Å—å —á—Ç–æ-—Ç–æ —Ä–∞–∑—É–º–Ω–æ–µ
            if cleaned and len(cleaned) > 1 and len(cleaned) < 50 and re.search(r'[–∞-—è—ë–ê-–Ø–Åa-zA-Z]', cleaned):
                return cleaned
            return ""
        except:
            return ""

    def _extract_rating(self, block) -> int:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ä–µ–π—Ç–∏–Ω–≥–∞ –∏–∑ –±–ª–æ–∫–∞ 2–ì–ò–°"""
        try:
            # –ò—â–µ–º SVG —ç–ª–µ–º–µ–Ω—Ç—ã —Å–æ –∑–≤—ë–∑–¥–∞–º–∏
            star_svgs = block.find_all('svg')
            for svg in star_svgs:
                # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã–µ –∑–≤—ë–∑–¥—ã –ø–æ —Ü–≤–µ—Ç—É
                paths = svg.find_all('path')
                filled_stars = 0
                for path in paths:
                    fill = path.get('fill', '')
                    if fill == 'black' or fill == '#000000':
                        filled_stars += 1
                
                if filled_stars > 0:
                    return min(filled_stars, 5)  # –ú–∞–∫—Å–∏–º—É–º 5 –∑–≤—ë–∑–¥
            
            return 0
        except:
            return 0

    def _extract_date(self, block) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞—Ç—ã –∏–∑ –±–ª–æ–∫–∞ 2–ì–ò–°"""
        try:
            # –ò—â–µ–º –¥–∞—Ç—É –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —Å–µ–ª–µ–∫—Ç–æ—Ä–µ
            date_element = block.find('div', class_='_1evjsdb')
            if date_element:
                date_text = date_element.get_text(strip=True)
                # –£–±–∏—Ä–∞–µ–º "–æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç" –µ—Å–ª–∏ –µ—Å—Ç—å
                date_text = re.sub(r',\s*–æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç', '', date_text, flags=re.IGNORECASE)
                cleaned_date = self._clean_date_text(date_text)
                if cleaned_date:
                    return cleaned_date
            
            # –ï—Å–ª–∏ –¥–∞—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–µ–∫—É—â—É—é –¥–∞—Ç—É
            from datetime import datetime
            return datetime.now().strftime('%Y-%m-%d')
        except:
            # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–µ–∫—É—â—É—é –¥–∞—Ç—É
            from datetime import datetime
            return datetime.now().strftime('%Y-%m-%d')

    def _clean_date_text(self, date_text: str) -> str:
        """–û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –¥–∞—Ç—ã –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ —á–∏—Å–ª–æ–≤–æ–π —Ñ–æ—Ä–º–∞—Ç YYYY-MM-DD"""
        try:
            # –ï—Å–ª–∏ —É–∂–µ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ YYYY-MM-DD, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
            if re.match(r'^\d{4}-\d{2}-\d{2}$', date_text.strip()):
                return date_text.strip()
            
            # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ –¥–∞—Ç—ã (—Ä—É—Å—Å–∫–∏–µ –∏ –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ)
            date_patterns = [
                r'\d{1,2}\s+(—è–Ω–≤–∞—Ä—è|—Ñ–µ–≤—Ä–∞–ª—è|–º–∞—Ä—Ç–∞|–∞–ø—Ä–µ–ª—è|–º–∞—è|–∏—é–Ω—è|–∏—é–ª—è|–∞–≤–≥—É—Å—Ç–∞|—Å–µ–Ω—Ç—è–±—Ä—è|–æ–∫—Ç—è–±—Ä—è|–Ω–æ—è–±—Ä—è|–¥–µ–∫–∞–±—Ä—è|january|february|march|april|may|june|july|august|september|october|november|december)\s+\d{4}',
                r'\d{1,2}\s+(—è–Ω–≤–∞—Ä—è|—Ñ–µ–≤—Ä–∞–ª—è|–º–∞—Ä—Ç–∞|–∞–ø—Ä–µ–ª—è|–º–∞—è|–∏—é–Ω—è|–∏—é–ª—è|–∞–≤–≥—É—Å—Ç–∞|—Å–µ–Ω—Ç—è–±—Ä—è|–æ–∫—Ç—è–±—Ä—è|–Ω–æ—è–±—Ä—è|–¥–µ–∫–∞–±—Ä—è|january|february|march|april|may|june|july|august|september|october|november|december)',
                r'\d{1,2}\.\d{1,2}\.\d{4}',
                r'(–≤—á–µ—Ä–∞|—Å–µ–≥–æ–¥–Ω—è|–ø–æ–∑–∞–≤—á–µ—Ä–∞)',
                r'\d+\s+(–¥–Ω—è|–¥–Ω–µ–π|–Ω–µ–¥–µ–ª–∏|–Ω–µ–¥–µ–ª—å|–º–µ—Å—è—Ü–∞|–º–µ—Å—è—Ü–µ–≤|–≥–æ–¥–∞|–ª–µ—Ç)\s+–Ω–∞–∑–∞–¥'
            ]
            
            for pattern in date_patterns:
                match = re.search(pattern, date_text, re.IGNORECASE)
                if match:
                    found_date = match.group(0)
                    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —á–∏—Å–ª–æ–≤–æ–π —Ñ–æ—Ä–º–∞—Ç
                    return self._convert_to_numeric_date(found_date)
            
            # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–µ–∫—É—â—É—é –¥–∞—Ç—É
            from datetime import datetime
            return datetime.now().strftime('%Y-%m-%d')
        except:
            # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–µ–∫—É—â—É—é –¥–∞—Ç—É
            from datetime import datetime
            return datetime.now().strftime('%Y-%m-%d')

    def _convert_to_numeric_date(self, date_text: str) -> str:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤–æ–π –¥–∞—Ç—ã –≤ —á–∏—Å–ª–æ–≤–æ–π —Ñ–æ—Ä–º–∞—Ç YYYY-MM-DD"""
        try:
            from datetime import datetime, timedelta
            
            # –°–ª–æ–≤–∞—Ä—å –º–µ—Å—è—Ü–µ–≤ (—Ä—É—Å—Å–∫–∏–µ –∏ –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ)
            months = {
                '—è–Ω–≤–∞—Ä—è': 1, '—Ñ–µ–≤—Ä–∞–ª—è': 2, '–º–∞—Ä—Ç–∞': 3, '–∞–ø—Ä–µ–ª—è': 4,
                '–º–∞—è': 5, '–∏—é–Ω—è': 6, '–∏—é–ª—è': 7, '–∞–≤–≥—É—Å—Ç–∞': 8,
                '—Å–µ–Ω—Ç—è–±—Ä—è': 9, '–æ–∫—Ç—è–±—Ä—è': 10, '–Ω–æ—è–±—Ä—è': 11, '–¥–µ–∫–∞–±—Ä—è': 12,
                'january': 1, 'february': 2, 'march': 3, 'april': 4,
                'may': 5, 'june': 6, 'july': 7, 'august': 8,
                'september': 9, 'october': 10, 'november': 11, 'december': 12
            }
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã—Ö –¥–∞—Ç
            if '—Å–µ–≥–æ–¥–Ω—è' in date_text.lower():
                return datetime.now().strftime('%Y-%m-%d')
            elif '–≤—á–µ—Ä–∞' in date_text.lower():
                yesterday = datetime.now() - timedelta(days=1)
                return yesterday.strftime('%Y-%m-%d')
            elif '–ø–æ–∑–∞–≤—á–µ—Ä–∞' in date_text.lower():
                day_before_yesterday = datetime.now() - timedelta(days=2)
                return day_before_yesterday.strftime('%Y-%m-%d')
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ "X –¥–Ω–µ–π –Ω–∞–∑–∞–¥"
            days_ago_match = re.search(r'(\d+)\s+(–¥–Ω—è|–¥–Ω–µ–π)\s+–Ω–∞–∑–∞–¥', date_text.lower())
            if days_ago_match:
                days = int(days_ago_match.group(1))
                past_date = datetime.now() - timedelta(days=days)
                return past_date.strftime('%Y-%m-%d')
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ "X –Ω–µ–¥–µ–ª—å –Ω–∞–∑–∞–¥"
            weeks_ago_match = re.search(r'(\d+)\s+(–Ω–µ–¥–µ–ª–∏|–Ω–µ–¥–µ–ª—å)\s+–Ω–∞–∑–∞–¥', date_text.lower())
            if weeks_ago_match:
                weeks = int(weeks_ago_match.group(1))
                past_date = datetime.now() - timedelta(weeks=weeks)
                return past_date.strftime('%Y-%m-%d')
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ "X –º–µ—Å—è—Ü–µ–≤ –Ω–∞–∑–∞–¥"
            months_ago_match = re.search(r'(\d+)\s+(–º–µ—Å—è—Ü–∞|–º–µ—Å—è—Ü–µ–≤)\s+–Ω–∞–∑–∞–¥', date_text.lower())
            if months_ago_match:
                months_count = int(months_ago_match.group(1))
                # –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ 30 –¥–Ω–µ–π –≤ –º–µ—Å—è—Ü–µ
                past_date = datetime.now() - timedelta(days=months_count * 30)
                return past_date.strftime('%Y-%m-%d')
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ "X –ª–µ—Ç –Ω–∞–∑–∞–¥"
            years_ago_match = re.search(r'(\d+)\s+(–≥–æ–¥–∞|–ª–µ—Ç)\s+–Ω–∞–∑–∞–¥', date_text.lower())
            if years_ago_match:
                years = int(years_ago_match.group(1))
                past_date = datetime.now() - timedelta(days=years * 365)
                return past_date.strftime('%Y-%m-%d')
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ–ª–Ω–æ–π –¥–∞—Ç—ã —Å –≥–æ–¥–æ–º: "2 –º–∞—è 2024"
            full_date_match = re.search(r'(\d{1,2})\s+(\w+)\s+(\d{4})', date_text)
            if full_date_match:
                day = int(full_date_match.group(1))
                month_name = full_date_match.group(2).lower()
                year = int(full_date_match.group(3))
                
                if month_name in months:
                    month = months[month_name]
                    return f"{year:04d}-{month:02d}-{day:02d}"
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞—Ç—ã –±–µ–∑ –≥–æ–¥–∞: "2 –º–∞—è" (–ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º —Ç–µ–∫—É—â–∏–π –≥–æ–¥)
            date_without_year_match = re.search(r'(\d{1,2})\s+(\w+)', date_text)
            if date_without_year_match:
                day = int(date_without_year_match.group(1))
                month_name = date_without_year_match.group(2).lower()
                
                if month_name in months:
                    month = months[month_name]
                    current_year = datetime.now().year
                    return f"{current_year:04d}-{month:02d}-{day:02d}"
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞ DD.MM.YYYY
            dot_date_match = re.search(r'(\d{1,2})\.(\d{1,2})\.(\d{4})', date_text)
            if dot_date_match:
                day = int(dot_date_match.group(1))
                month = int(dot_date_match.group(2))
                year = int(dot_date_match.group(3))
                return f"{year:04d}-{month:02d}-{day:02d}"
            
            # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –ø–æ–¥–æ—à–ª–æ, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
            return date_text
            
        except Exception as e:
            self.logger.debug(f"–û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –¥–∞—Ç—ã '{date_text}': {e}")
            return date_text

    def save_reviews_to_csv(self, reviews: List[Dict], filename: str):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –æ—Ç–∑—ã–≤–æ–≤ –≤ CSV (–ø–µ—Ä–µ–∑–∞–ø–∏—Å—å —Ñ–∞–π–ª–∞)"""
        if not reviews:
            self.logger.warning("–ù–µ—Ç –æ—Ç–∑—ã–≤–æ–≤ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
            return
        
        try:
            fieldnames = ['id', 'text', 'rating', 'author', 'date', 'source']
            
            # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–π CSV —Ñ–∞–π–ª –µ—Å–ª–∏ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
            if os.path.exists(filename):
                os.remove(filename)
                self.logger.info(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω —Å—Ç–∞—Ä—ã–π CSV —Ñ–∞–π–ª: {filename}")
            
            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π CSV —Ñ–∞–π–ª —Å –∞–∫—Ç—É–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
            with open(filename, 'w', newline='', encoding='utf-8') as csvfile:
                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
                writer.writeheader()
                writer.writerows(reviews)
            
            self.logger.info(f"üíæ –û–±–Ω–æ–≤–ª–µ–Ω CSV —Ñ–∞–π–ª: {filename} ({len(reviews)} –æ—Ç–∑—ã–≤–æ–≤)")
            
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è CSV: {e}")


